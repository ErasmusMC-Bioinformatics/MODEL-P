{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split,cross_val_score,StratifiedKFold,KFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,silhouette_score,calinski_harabasz_score\n",
    "from sklearn.feature_selection import SelectKBest,f_classif,SelectFdr\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize,RobustScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from lifelines import CoxPHFitter\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import glorot_uniform,RandomUniform,Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "methy = pandas.read_csv(\"input data/methylation2.csv\")\n",
    "mrna = pandas.read_csv(\"input data/mrna.csv\")\n",
    "mirna = pandas.read_csv(\"input data/mirna.csv\")\n",
    "clinical_new = pandas.read_csv(\"clinical_data3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean up the training sets\n",
    "\n",
    "# drop redundant columns \n",
    "methy = methy.drop(['Unnamed: 0'], axis=1)\n",
    "mrna = mrna.drop(['Unnamed: 0'], axis=1)\n",
    "mirna = mirna.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "clinical_new = clinical_new.drop(['Unnamed: 0'], axis = 1)\n",
    "clinical_new = clinical_new[['bcr_patient_barcode','vital_status','survival','cause_of_death']]\n",
    "\n",
    "# reset index\n",
    "mrna = mrna.set_index(['Group.1'])\n",
    "mirna = mirna.set_index(['GeneSymbol'])\n",
    "\n",
    "clinical_new.reset_index(inplace=True)\n",
    "# transpose\n",
    "methy = methy.transpose()\n",
    "mrna = mrna.transpose()\n",
    "mirna = mirna.transpose()\n",
    "\n",
    "# vital status has to be 0/1 not 1/2\n",
    "clinical_new[[\"vital_status\"]] = clinical_new[[\"vital_status\"]] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data log2 transformation\n",
    "mrna = np.log2(mrna+1)\n",
    "mirna = np.log2(mirna+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# concatenate the multi-omics data\n",
    "data_all = pandas.concat([methy,mrna,mirna],axis = 1)\n",
    "data_all2 = data_all.loc[clinical_new['bcr_patient_barcode'],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train autoencoder for 146 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ae(X_train):\n",
    "    # normalize each data type set\n",
    "\n",
    "    # split dataset into multi omics data\n",
    "    methy_train = X_train.iloc[:,0:20980]\n",
    "    mrna_train = X_train.iloc[:,20980:38168]\n",
    "    mirna_train = X_train.iloc[:,38168:38597]\n",
    "\n",
    "    # l2 normalization,sample norm\n",
    "    methy_train = normalize(methy_train, norm='l2',axis = 1)\n",
    "    mrna_train = normalize(mrna_train, norm='l2',axis = 1)\n",
    "    mirna_train = normalize(mirna_train, norm='l2',axis = 1)\n",
    "\n",
    "    data = pandas.concat([pandas.DataFrame(methy_train),pandas.DataFrame(mrna_train),pandas.DataFrame(mirna_train)],axis = 1)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coxph_feature_selection(data,clinical_data):\n",
    "    p_value = []\n",
    "    cph = CoxPHFitter()\n",
    "    for j in range(0,len(data.columns)):\n",
    "        data_label = pandas.concat([data[j],clinical_data[[\"survival\",\"vital_status\"]]],axis = 1)\n",
    "        cph.fit(data_label, duration_col=\"survival\", event_col=\"vital_status\")\n",
    "        # get p value\n",
    "        if cph.summary.iloc[0,4] <0.05:\n",
    "            p_value.append(j)\n",
    "            # print(j)\n",
    "    data_new = data[p_value]\n",
    "    #print(len(p_value))    \n",
    "    return data_new         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_function(data,cluster):\n",
    "    for n in range(2,6):\n",
    "        kmeans = KMeans(n_clusters=n, n_init =10).fit(data)\n",
    "        labels = kmeans.labels_\n",
    "        # print(silhouette_score(data, labels))\n",
    "        # print(calinski_harabasz_score(data, labels))\n",
    "    kmeans = KMeans(n_clusters=cluster, n_init=10).fit(data)\n",
    "    labels = kmeans.labels_\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_num = 1000\n",
    "\n",
    "def paad_model(activation = \"tanh\",hidden_layers = 500, bottleneck = 100,l2 = 0.001,l1=0.001):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(hidden_layers,activation= activation,input_shape=(38597,),kernel_regularizer=regularizers.l2(l2),\n",
    "                    activity_regularizer=regularizers.l1(l1),kernel_initializer=glorot_uniform(seed = seed_num)))#             \n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(bottleneck, activation=activation,kernel_initializer=glorot_uniform(seed = seed_num)))\n",
    "    #,random_uniform,Constant(value=0.005),glorot_uniform\n",
    "                    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(hidden_layers, activation=activation,kernel_initializer=glorot_uniform(seed = seed_num))) \n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(38597, activation=activation,kernel_initializer=glorot_uniform(seed = seed_num)))\n",
    "    \n",
    "    model.compile(loss='mean_squared_logarithmic_error',optimizer='sgd') #,mean_squared_error\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 146 samples\n",
      "Epoch 1/10\n",
      "146/146 [==============================] - 16s 113ms/sample - loss: 0.9848\n",
      "Epoch 2/10\n",
      "146/146 [==============================] - 16s 109ms/sample - loss: 0.9790\n",
      "Epoch 3/10\n",
      "146/146 [==============================] - 16s 110ms/sample - loss: 0.9733\n",
      "Epoch 4/10\n",
      "146/146 [==============================] - 16s 111ms/sample - loss: 0.9676\n",
      "Epoch 5/10\n",
      "146/146 [==============================] - 16s 111ms/sample - loss: 0.9619\n",
      "Epoch 6/10\n",
      "146/146 [==============================] - 16s 111ms/sample - loss: 0.9563\n",
      "Epoch 7/10\n",
      "146/146 [==============================] - 16s 111ms/sample - loss: 0.9507\n",
      "Epoch 8/10\n",
      "146/146 [==============================] - 17s 114ms/sample - loss: 0.9452\n",
      "Epoch 9/10\n",
      "146/146 [==============================] - 16s 111ms/sample - loss: 0.9396\n",
      "Epoch 10/10\n",
      "146/146 [==============================] - 16s 111ms/sample - loss: 0.9342\n"
     ]
    }
   ],
   "source": [
    "df = normalize_ae(data_all2)\n",
    "\n",
    "model = paad_model('tanh',500,200,0.001,0.0001)\n",
    "autoencoder_train = model.fit(x=df, y=df, epochs=10, batch_size=1) #,validation_split=0.2\n",
    "\n",
    "# get bottleneck layer\n",
    "layers = backend.function([model.layers[0].input],[model.layers[2].output])\n",
    "feature_new = pandas.DataFrame(layers([df])[0])\n",
    "\n",
    "# calculate p value\n",
    "df_new = coxph_feature_selection(feature_new,clinical_new)\n",
    "label_all = kmeans_function(df_new,2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
